{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "train_images = np.load('../../data/processed/train_images.npy')\n",
    "train_labels = np.load('../../data/processed/train_labels.npy')\n",
    "test_images = np.load('../../data/processed/test_images.npy')\n",
    "test_labels = np.load('../../data/processed/test_labels.npy')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "test_labels = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')  # Number of mood classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "898/898 [==============================] - 76s 84ms/step - loss: 1.7990 - accuracy: 0.2516 - val_loss: 1.7273 - val_accuracy: 0.2874\n",
      "Epoch 2/20\n",
      "898/898 [==============================] - 83s 92ms/step - loss: 1.7520 - accuracy: 0.2764 - val_loss: 1.6986 - val_accuracy: 0.3040\n",
      "Epoch 3/20\n",
      "898/898 [==============================] - 89s 99ms/step - loss: 1.7091 - accuracy: 0.3022 - val_loss: 1.5585 - val_accuracy: 0.3828\n",
      "Epoch 4/20\n",
      "898/898 [==============================] - 79s 88ms/step - loss: 1.6306 - accuracy: 0.3504 - val_loss: 1.4286 - val_accuracy: 0.4585\n",
      "Epoch 5/20\n",
      "898/898 [==============================] - 80s 89ms/step - loss: 1.5556 - accuracy: 0.3917 - val_loss: 1.4169 - val_accuracy: 0.4465\n",
      "Epoch 6/20\n",
      "898/898 [==============================] - 82s 91ms/step - loss: 1.5087 - accuracy: 0.4121 - val_loss: 1.3405 - val_accuracy: 0.4889\n",
      "Epoch 7/20\n",
      "898/898 [==============================] - 80s 89ms/step - loss: 1.4709 - accuracy: 0.4319 - val_loss: 1.3097 - val_accuracy: 0.5040\n",
      "Epoch 8/20\n",
      "898/898 [==============================] - 79s 87ms/step - loss: 1.4445 - accuracy: 0.4441 - val_loss: 1.3049 - val_accuracy: 0.4987\n",
      "Epoch 9/20\n",
      "898/898 [==============================] - 82s 92ms/step - loss: 1.4178 - accuracy: 0.4537 - val_loss: 1.2752 - val_accuracy: 0.5117\n",
      "Epoch 10/20\n",
      "898/898 [==============================] - 79s 88ms/step - loss: 1.4016 - accuracy: 0.4632 - val_loss: 1.2517 - val_accuracy: 0.5234\n",
      "Epoch 11/20\n",
      "898/898 [==============================] - 79s 88ms/step - loss: 1.3916 - accuracy: 0.4684 - val_loss: 1.2783 - val_accuracy: 0.5148\n",
      "Epoch 12/20\n",
      "898/898 [==============================] - 80s 89ms/step - loss: 1.3740 - accuracy: 0.4726 - val_loss: 1.2378 - val_accuracy: 0.5269\n",
      "Epoch 13/20\n",
      "898/898 [==============================] - 81s 90ms/step - loss: 1.3603 - accuracy: 0.4795 - val_loss: 1.2193 - val_accuracy: 0.5337\n",
      "Epoch 14/20\n",
      "898/898 [==============================] - 80s 89ms/step - loss: 1.3587 - accuracy: 0.4809 - val_loss: 1.2541 - val_accuracy: 0.5227\n",
      "Epoch 15/20\n",
      "898/898 [==============================] - 80s 89ms/step - loss: 1.3507 - accuracy: 0.4855 - val_loss: 1.2361 - val_accuracy: 0.5332\n",
      "Epoch 16/20\n",
      "898/898 [==============================] - 81s 91ms/step - loss: 1.3389 - accuracy: 0.4896 - val_loss: 1.2104 - val_accuracy: 0.5442\n",
      "Epoch 17/20\n",
      "898/898 [==============================] - 83s 92ms/step - loss: 1.3332 - accuracy: 0.4905 - val_loss: 1.1963 - val_accuracy: 0.5403\n",
      "Epoch 18/20\n",
      "898/898 [==============================] - 80s 89ms/step - loss: 1.3304 - accuracy: 0.4882 - val_loss: 1.2026 - val_accuracy: 0.5410\n",
      "Epoch 19/20\n",
      "898/898 [==============================] - 80s 89ms/step - loss: 1.3175 - accuracy: 0.4949 - val_loss: 1.2012 - val_accuracy: 0.5432\n",
      "Epoch 20/20\n",
      "898/898 [==============================] - 83s 92ms/step - loss: 1.3180 - accuracy: 0.4996 - val_loss: 1.2091 - val_accuracy: 0.5419\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    epochs=20,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 - 3s - loss: 1.2091 - accuracy: 0.5419 - 3s/epoch - 12ms/step\n",
      "Test Accuracy: 0.5419337153434753\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('../../models/mood_cnn_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
